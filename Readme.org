* Setup and run SIRIUS on LUMI-G

This is a workaround to install q-sirius on lumi-g. First sirius is installed
via spack and then q-e-sirius is installed manually using the dependencies and cray-mpich
from spack. The two step process is required because the systemwide rocm
installation has been modified s.t. that it doesn't work with spack/gfortran,
and because rocm cannot be installed via spack in practice due to filesystem
limitation/compilation time.

** Preparation
- You should have received =cray-mpich-binary-8.1.29.tar.gz=. Copy it to your home directory and adapt the =url= in the recipe accordingly:
[[file:repo/packages/cray-mpich/package.py][link]]
- Replace =<projid>= in [[file:spack-setup/setup::projid=<projid>]] by your project id.
- git clone spack v0.23 in scratch filesystem
#+begin_src bash
  # create the directory <username> in scratch beforehand
  projid=465001618 # use your own projid
  cd /scratch/project_$projid/$(whoami)
  git clone --depth=1 -b releases/v0.23 https://github.com/spack/spack
#+end_src

** Configuration files for spack and custom spack repository

We are using a custom spack configruation, where the rocm packages are setup as external dependencies, using the official version on LUMI (rocm 6.0.3).

#+begin_src bash
spack-setup
├── setup
└── spack-config
    ├── compilers.yaml
    ├── config.yaml
    ├── modules.yaml
    └── packages.yaml
#+end_src

In =repo= there is a custom spack recipe for =cray-mpich=. This is using a binary tarball of =cray-mpich@8.1.29=. It allows to use GPU direct communication, if this isn't required, in principle the usual external/module based cray-mpich can be used.

** Spack environment

An example is provided in [[file:sirius-env]] to compile SIRIUS for the LUMI-G partition.

~spack.yaml~
#+begin_src yaml
  spack:
    view: true
    specs:
    - sirius@develop+rocm+magma+apps+fortran build_type=Release
    packages:
      all:
        variants: amdgpu_target=gfx90a amdgpu_target_sram_ecc=gfx90a
        target: [zen3]
      openblas:
        require: [threads=openmp]
      cray-mpich:
        require: ['@8.1.29+rocm']
    repos:
    - ./repo
    concretizer:
      targets:
        host_compatible: false
      unify: true
#+end_src


** Compile SIRIUS

#+begin_src bash
  # TODO: adapt first projid, location of git clone https://github.com/spack/spack.git as needed
  source spack-setup/setup
  # activate the anonymous spack environment for sirius (directory containing spack.yaml)
  spack env activate ./sirius-env
  # check concretization output before install
  spack concretize -f
  spack install
#+end_src

** Compile QE-SIRIUS

QE-SIRIUS can be installed via spack. Unfortunately not on lumi, because the
systemwide rocm installation contains fortran mod files from llvm, these are
incompatible with gfortran. Therefore it's not possible to install QE using
spack. In principle rocm could be installed in spack, however, the slow filesystem (and
possibly insufficient inode qutoa) makes this almost impossible.

Preparation (download QE-SIRIUS)
#+begin_src bash
  cd /scratch/project_xxxx/$(whoami)
  curl -L https://github.com/electronic-structure/q-e-sirius/archive/refs/tags/q-e-sirius/1.0.1.tar.gz | tar -xzf -
#+end_src

Replace =QESIRIUS_DIR= in =build-qe.sh= by the corresponding directory in SCRATCH.

Compilation
#+begin_src bash
 spack -e ./sirius-env load --sh sirius > ./sirius-env/sirius.load
 source sirius.load
  ./build-qe.sh
#+end_src

This is done in scratch because (inode) quota in home might be insufficient. The SIRIUS-enabled pw.x will be installed to `./qebin`.

** Run QE-SIRIUS
An example sbatch file is in  [[file:example-sbatch]].
